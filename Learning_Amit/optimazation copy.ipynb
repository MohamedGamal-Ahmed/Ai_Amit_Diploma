{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "fk_GlFi5VbEe"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Zeet7_unV1zg"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CustomerID</th>\n",
              "      <th>Count</th>\n",
              "      <th>Country</th>\n",
              "      <th>State</th>\n",
              "      <th>City</th>\n",
              "      <th>Zip Code</th>\n",
              "      <th>Lat Long</th>\n",
              "      <th>Latitude</th>\n",
              "      <th>Longitude</th>\n",
              "      <th>Gender</th>\n",
              "      <th>...</th>\n",
              "      <th>Contract</th>\n",
              "      <th>Paperless Billing</th>\n",
              "      <th>Payment Method</th>\n",
              "      <th>Monthly Charges</th>\n",
              "      <th>Total Charges</th>\n",
              "      <th>Churn Label</th>\n",
              "      <th>Churn Value</th>\n",
              "      <th>Churn Score</th>\n",
              "      <th>CLTV</th>\n",
              "      <th>Churn Reason</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3668-QPYBK</td>\n",
              "      <td>1</td>\n",
              "      <td>United States</td>\n",
              "      <td>California</td>\n",
              "      <td>Los Angeles</td>\n",
              "      <td>90003</td>\n",
              "      <td>33.964131, -118.272783</td>\n",
              "      <td>33.964131</td>\n",
              "      <td>-118.272783</td>\n",
              "      <td>Male</td>\n",
              "      <td>...</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Mailed check</td>\n",
              "      <td>53.85</td>\n",
              "      <td>108.15</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1</td>\n",
              "      <td>86</td>\n",
              "      <td>3239</td>\n",
              "      <td>Competitor made better offer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9237-HQITU</td>\n",
              "      <td>1</td>\n",
              "      <td>United States</td>\n",
              "      <td>California</td>\n",
              "      <td>Los Angeles</td>\n",
              "      <td>90005</td>\n",
              "      <td>34.059281, -118.30742</td>\n",
              "      <td>34.059281</td>\n",
              "      <td>-118.307420</td>\n",
              "      <td>Female</td>\n",
              "      <td>...</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Electronic check</td>\n",
              "      <td>70.70</td>\n",
              "      <td>151.65</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1</td>\n",
              "      <td>67</td>\n",
              "      <td>2701</td>\n",
              "      <td>Moved</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9305-CDSKC</td>\n",
              "      <td>1</td>\n",
              "      <td>United States</td>\n",
              "      <td>California</td>\n",
              "      <td>Los Angeles</td>\n",
              "      <td>90006</td>\n",
              "      <td>34.048013, -118.293953</td>\n",
              "      <td>34.048013</td>\n",
              "      <td>-118.293953</td>\n",
              "      <td>Female</td>\n",
              "      <td>...</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Electronic check</td>\n",
              "      <td>99.65</td>\n",
              "      <td>820.5</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1</td>\n",
              "      <td>86</td>\n",
              "      <td>5372</td>\n",
              "      <td>Moved</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7892-POOKP</td>\n",
              "      <td>1</td>\n",
              "      <td>United States</td>\n",
              "      <td>California</td>\n",
              "      <td>Los Angeles</td>\n",
              "      <td>90010</td>\n",
              "      <td>34.062125, -118.315709</td>\n",
              "      <td>34.062125</td>\n",
              "      <td>-118.315709</td>\n",
              "      <td>Female</td>\n",
              "      <td>...</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Electronic check</td>\n",
              "      <td>104.80</td>\n",
              "      <td>3046.05</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1</td>\n",
              "      <td>84</td>\n",
              "      <td>5003</td>\n",
              "      <td>Moved</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0280-XJGEX</td>\n",
              "      <td>1</td>\n",
              "      <td>United States</td>\n",
              "      <td>California</td>\n",
              "      <td>Los Angeles</td>\n",
              "      <td>90015</td>\n",
              "      <td>34.039224, -118.266293</td>\n",
              "      <td>34.039224</td>\n",
              "      <td>-118.266293</td>\n",
              "      <td>Male</td>\n",
              "      <td>...</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Bank transfer (automatic)</td>\n",
              "      <td>103.70</td>\n",
              "      <td>5036.3</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>5340</td>\n",
              "      <td>Competitor had better devices</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 33 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   CustomerID  Count        Country       State         City  Zip Code  \\\n",
              "0  3668-QPYBK      1  United States  California  Los Angeles     90003   \n",
              "1  9237-HQITU      1  United States  California  Los Angeles     90005   \n",
              "2  9305-CDSKC      1  United States  California  Los Angeles     90006   \n",
              "3  7892-POOKP      1  United States  California  Los Angeles     90010   \n",
              "4  0280-XJGEX      1  United States  California  Los Angeles     90015   \n",
              "\n",
              "                 Lat Long   Latitude   Longitude  Gender  ...        Contract  \\\n",
              "0  33.964131, -118.272783  33.964131 -118.272783    Male  ...  Month-to-month   \n",
              "1   34.059281, -118.30742  34.059281 -118.307420  Female  ...  Month-to-month   \n",
              "2  34.048013, -118.293953  34.048013 -118.293953  Female  ...  Month-to-month   \n",
              "3  34.062125, -118.315709  34.062125 -118.315709  Female  ...  Month-to-month   \n",
              "4  34.039224, -118.266293  34.039224 -118.266293    Male  ...  Month-to-month   \n",
              "\n",
              "  Paperless Billing             Payment Method  Monthly Charges Total Charges  \\\n",
              "0               Yes               Mailed check            53.85        108.15   \n",
              "1               Yes           Electronic check            70.70        151.65   \n",
              "2               Yes           Electronic check            99.65         820.5   \n",
              "3               Yes           Electronic check           104.80       3046.05   \n",
              "4               Yes  Bank transfer (automatic)           103.70        5036.3   \n",
              "\n",
              "  Churn Label Churn Value Churn Score  CLTV                   Churn Reason  \n",
              "0         Yes           1          86  3239   Competitor made better offer  \n",
              "1         Yes           1          67  2701                          Moved  \n",
              "2         Yes           1          86  5372                          Moved  \n",
              "3         Yes           1          84  5003                          Moved  \n",
              "4         Yes           1          89  5340  Competitor had better devices  \n",
              "\n",
              "[5 rows x 33 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.read_excel(\"Telco_customer_churn.xlsx\")\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "uNPKO1oYV7CX",
        "outputId": "0249c24f-7fc1-4593-c645-1e64042ef3ec"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CustomerID</th>\n",
              "      <th>Count</th>\n",
              "      <th>Country</th>\n",
              "      <th>State</th>\n",
              "      <th>City</th>\n",
              "      <th>Zip Code</th>\n",
              "      <th>Lat Long</th>\n",
              "      <th>Latitude</th>\n",
              "      <th>Longitude</th>\n",
              "      <th>Gender</th>\n",
              "      <th>...</th>\n",
              "      <th>Contract</th>\n",
              "      <th>Paperless Billing</th>\n",
              "      <th>Payment Method</th>\n",
              "      <th>Monthly Charges</th>\n",
              "      <th>Total Charges</th>\n",
              "      <th>Churn Label</th>\n",
              "      <th>Churn Value</th>\n",
              "      <th>Churn Score</th>\n",
              "      <th>CLTV</th>\n",
              "      <th>Churn Reason</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3668-QPYBK</td>\n",
              "      <td>1</td>\n",
              "      <td>United States</td>\n",
              "      <td>California</td>\n",
              "      <td>Los Angeles</td>\n",
              "      <td>90003</td>\n",
              "      <td>33.964131, -118.272783</td>\n",
              "      <td>33.964131</td>\n",
              "      <td>-118.272783</td>\n",
              "      <td>Male</td>\n",
              "      <td>...</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Mailed check</td>\n",
              "      <td>53.85</td>\n",
              "      <td>108.15</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1</td>\n",
              "      <td>86</td>\n",
              "      <td>3239</td>\n",
              "      <td>Competitor made better offer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9237-HQITU</td>\n",
              "      <td>1</td>\n",
              "      <td>United States</td>\n",
              "      <td>California</td>\n",
              "      <td>Los Angeles</td>\n",
              "      <td>90005</td>\n",
              "      <td>34.059281, -118.30742</td>\n",
              "      <td>34.059281</td>\n",
              "      <td>-118.307420</td>\n",
              "      <td>Female</td>\n",
              "      <td>...</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Electronic check</td>\n",
              "      <td>70.70</td>\n",
              "      <td>151.65</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1</td>\n",
              "      <td>67</td>\n",
              "      <td>2701</td>\n",
              "      <td>Moved</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9305-CDSKC</td>\n",
              "      <td>1</td>\n",
              "      <td>United States</td>\n",
              "      <td>California</td>\n",
              "      <td>Los Angeles</td>\n",
              "      <td>90006</td>\n",
              "      <td>34.048013, -118.293953</td>\n",
              "      <td>34.048013</td>\n",
              "      <td>-118.293953</td>\n",
              "      <td>Female</td>\n",
              "      <td>...</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Electronic check</td>\n",
              "      <td>99.65</td>\n",
              "      <td>820.5</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1</td>\n",
              "      <td>86</td>\n",
              "      <td>5372</td>\n",
              "      <td>Moved</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7892-POOKP</td>\n",
              "      <td>1</td>\n",
              "      <td>United States</td>\n",
              "      <td>California</td>\n",
              "      <td>Los Angeles</td>\n",
              "      <td>90010</td>\n",
              "      <td>34.062125, -118.315709</td>\n",
              "      <td>34.062125</td>\n",
              "      <td>-118.315709</td>\n",
              "      <td>Female</td>\n",
              "      <td>...</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Electronic check</td>\n",
              "      <td>104.80</td>\n",
              "      <td>3046.05</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1</td>\n",
              "      <td>84</td>\n",
              "      <td>5003</td>\n",
              "      <td>Moved</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0280-XJGEX</td>\n",
              "      <td>1</td>\n",
              "      <td>United States</td>\n",
              "      <td>California</td>\n",
              "      <td>Los Angeles</td>\n",
              "      <td>90015</td>\n",
              "      <td>34.039224, -118.266293</td>\n",
              "      <td>34.039224</td>\n",
              "      <td>-118.266293</td>\n",
              "      <td>Male</td>\n",
              "      <td>...</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Bank transfer (automatic)</td>\n",
              "      <td>103.70</td>\n",
              "      <td>5036.3</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>5340</td>\n",
              "      <td>Competitor had better devices</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 33 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   CustomerID  Count        Country       State         City  Zip Code  \\\n",
              "0  3668-QPYBK      1  United States  California  Los Angeles     90003   \n",
              "1  9237-HQITU      1  United States  California  Los Angeles     90005   \n",
              "2  9305-CDSKC      1  United States  California  Los Angeles     90006   \n",
              "3  7892-POOKP      1  United States  California  Los Angeles     90010   \n",
              "4  0280-XJGEX      1  United States  California  Los Angeles     90015   \n",
              "\n",
              "                 Lat Long   Latitude   Longitude  Gender  ...        Contract  \\\n",
              "0  33.964131, -118.272783  33.964131 -118.272783    Male  ...  Month-to-month   \n",
              "1   34.059281, -118.30742  34.059281 -118.307420  Female  ...  Month-to-month   \n",
              "2  34.048013, -118.293953  34.048013 -118.293953  Female  ...  Month-to-month   \n",
              "3  34.062125, -118.315709  34.062125 -118.315709  Female  ...  Month-to-month   \n",
              "4  34.039224, -118.266293  34.039224 -118.266293    Male  ...  Month-to-month   \n",
              "\n",
              "  Paperless Billing             Payment Method  Monthly Charges Total Charges  \\\n",
              "0               Yes               Mailed check            53.85        108.15   \n",
              "1               Yes           Electronic check            70.70        151.65   \n",
              "2               Yes           Electronic check            99.65         820.5   \n",
              "3               Yes           Electronic check           104.80       3046.05   \n",
              "4               Yes  Bank transfer (automatic)           103.70        5036.3   \n",
              "\n",
              "  Churn Label Churn Value Churn Score  CLTV                   Churn Reason  \n",
              "0         Yes           1          86  3239   Competitor made better offer  \n",
              "1         Yes           1          67  2701                          Moved  \n",
              "2         Yes           1          86  5372                          Moved  \n",
              "3         Yes           1          84  5003                          Moved  \n",
              "4         Yes           1          89  5340  Competitor had better devices  \n",
              "\n",
              "[5 rows x 33 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Frn7ARvdV_LW"
      },
      "outputs": [],
      "source": [
        "def data_info(data):\n",
        "    cols=[]\n",
        "    unique_val=[]\n",
        "    n_uniques=[]\n",
        "    dtypes=[]\n",
        "    nulls=[]\n",
        "    for col in data.columns:\n",
        "        cols.append(col)\n",
        "        dtypes.append(data[col].dtype)\n",
        "        n_uniques.append(data[col].nunique())\n",
        "        unique_val.append(data[col].unique())\n",
        "        nulls.append(data[col].isna().sum())\n",
        "\n",
        "    return pd.DataFrame({\"Col\":cols,\"dtype\":dtypes,\"n_uniques\":n_uniques,\"Unique Values\":unique_val,\"Nulls\":nulls})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Vl1FAKreWFCL"
      },
      "outputs": [],
      "source": [
        "data.drop(['CustomerID','Churn Label','Count','Country','State','Zip Code','Lat Long','City'],axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "UWvhwnPxWLG6"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le=LabelEncoder()\n",
        "data['Contract']=le.fit_transform(data['Contract'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "k1VjfH5zWOHH",
        "outputId": "68215eba-5a6a-4f18-8a16-142442c37690"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Churn Value\n",
              "0    5174\n",
              "1    1869\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data['Churn Value'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCcJNdfbWTFJ",
        "outputId": "be63c042-9cc2-4060-86a8-accc7493ec33"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Mgama\\AppData\\Local\\Temp\\ipykernel_26420\\3116493132.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data['Churn Reason'].fillna(\"not leave\",inplace=True)\n"
          ]
        }
      ],
      "source": [
        "data['Churn Reason'].fillna(\"not leave\",inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "LbbJIGAHWXY1"
      },
      "outputs": [],
      "source": [
        "data['Total Charges']=pd.to_numeric(data['Total Charges'],errors='coerce')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKJBNuQlWfFH",
        "outputId": "a33b6b23-8046-4c7a-f995-0fdfc8133584"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Mgama\\AppData\\Local\\Temp\\ipykernel_26420\\2330687429.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data['Total Charges'].fillna(data['Total Charges'].mean(),inplace=True)\n"
          ]
        }
      ],
      "source": [
        "data['Total Charges'].fillna(data['Total Charges'].mean(),inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "id": "Z71gRrF-WhQy",
        "outputId": "86c8f16d-bab5-4bdb-e9e3-47601641b516"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Latitude</th>\n",
              "      <th>Longitude</th>\n",
              "      <th>Tenure Months</th>\n",
              "      <th>Contract</th>\n",
              "      <th>Monthly Charges</th>\n",
              "      <th>Total Charges</th>\n",
              "      <th>Churn Value</th>\n",
              "      <th>Churn Score</th>\n",
              "      <th>CLTV</th>\n",
              "      <th>Gender_Male</th>\n",
              "      <th>...</th>\n",
              "      <th>Churn Reason_Limited range of services</th>\n",
              "      <th>Churn Reason_Long distance charges</th>\n",
              "      <th>Churn Reason_Moved</th>\n",
              "      <th>Churn Reason_Network reliability</th>\n",
              "      <th>Churn Reason_Poor expertise of online support</th>\n",
              "      <th>Churn Reason_Poor expertise of phone support</th>\n",
              "      <th>Churn Reason_Price too high</th>\n",
              "      <th>Churn Reason_Product dissatisfaction</th>\n",
              "      <th>Churn Reason_Service dissatisfaction</th>\n",
              "      <th>Churn Reason_not leave</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>33.964131</td>\n",
              "      <td>-118.272783</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>53.85</td>\n",
              "      <td>108.15</td>\n",
              "      <td>1</td>\n",
              "      <td>86</td>\n",
              "      <td>3239</td>\n",
              "      <td>True</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>34.059281</td>\n",
              "      <td>-118.307420</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>70.70</td>\n",
              "      <td>151.65</td>\n",
              "      <td>1</td>\n",
              "      <td>67</td>\n",
              "      <td>2701</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>34.048013</td>\n",
              "      <td>-118.293953</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>99.65</td>\n",
              "      <td>820.50</td>\n",
              "      <td>1</td>\n",
              "      <td>86</td>\n",
              "      <td>5372</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>34.062125</td>\n",
              "      <td>-118.315709</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>104.80</td>\n",
              "      <td>3046.05</td>\n",
              "      <td>1</td>\n",
              "      <td>84</td>\n",
              "      <td>5003</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>34.039224</td>\n",
              "      <td>-118.266293</td>\n",
              "      <td>49</td>\n",
              "      <td>0</td>\n",
              "      <td>103.70</td>\n",
              "      <td>5036.30</td>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>5340</td>\n",
              "      <td>True</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 54 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    Latitude   Longitude  Tenure Months  Contract  Monthly Charges  \\\n",
              "0  33.964131 -118.272783              2         0            53.85   \n",
              "1  34.059281 -118.307420              2         0            70.70   \n",
              "2  34.048013 -118.293953              8         0            99.65   \n",
              "3  34.062125 -118.315709             28         0           104.80   \n",
              "4  34.039224 -118.266293             49         0           103.70   \n",
              "\n",
              "   Total Charges  Churn Value  Churn Score  CLTV  Gender_Male  ...  \\\n",
              "0         108.15            1           86  3239         True  ...   \n",
              "1         151.65            1           67  2701        False  ...   \n",
              "2         820.50            1           86  5372        False  ...   \n",
              "3        3046.05            1           84  5003        False  ...   \n",
              "4        5036.30            1           89  5340         True  ...   \n",
              "\n",
              "   Churn Reason_Limited range of services  Churn Reason_Long distance charges  \\\n",
              "0                                   False                               False   \n",
              "1                                   False                               False   \n",
              "2                                   False                               False   \n",
              "3                                   False                               False   \n",
              "4                                   False                               False   \n",
              "\n",
              "   Churn Reason_Moved  Churn Reason_Network reliability  \\\n",
              "0               False                             False   \n",
              "1                True                             False   \n",
              "2                True                             False   \n",
              "3                True                             False   \n",
              "4               False                             False   \n",
              "\n",
              "   Churn Reason_Poor expertise of online support  \\\n",
              "0                                          False   \n",
              "1                                          False   \n",
              "2                                          False   \n",
              "3                                          False   \n",
              "4                                          False   \n",
              "\n",
              "   Churn Reason_Poor expertise of phone support  Churn Reason_Price too high  \\\n",
              "0                                         False                        False   \n",
              "1                                         False                        False   \n",
              "2                                         False                        False   \n",
              "3                                         False                        False   \n",
              "4                                         False                        False   \n",
              "\n",
              "   Churn Reason_Product dissatisfaction  Churn Reason_Service dissatisfaction  \\\n",
              "0                                 False                                 False   \n",
              "1                                 False                                 False   \n",
              "2                                 False                                 False   \n",
              "3                                 False                                 False   \n",
              "4                                 False                                 False   \n",
              "\n",
              "   Churn Reason_not leave  \n",
              "0                   False  \n",
              "1                   False  \n",
              "2                   False  \n",
              "3                   False  \n",
              "4                   False  \n",
              "\n",
              "[5 rows x 54 columns]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data=pd.get_dummies(data,drop_first=True)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "1eihrnAhWleG"
      },
      "outputs": [],
      "source": [
        "X=data.drop(['Churn Value'],axis=1).values\n",
        "y=data['Churn Value'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "PbXf6K62Wn_4"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_X,test_X,train_y,test_y=train_test_split(X,y,test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "HvT6sbi9Wpxo"
      },
      "outputs": [],
      "source": [
        "#fearture scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sd=StandardScaler()\n",
        "\n",
        "\n",
        "\n",
        "train_X=sd.fit_transform(train_X)\n",
        "test_X=sd.transform(test_X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "AgdmJOCoWrnS"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Mgama\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,700</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,530</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │         \u001b[38;5;34m2,700\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │         \u001b[38;5;34m1,530\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m31\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,261</span> (16.64 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,261\u001b[0m (16.64 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,261</span> (16.64 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,261\u001b[0m (16.64 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(50,activation='relu',input_shape=(train_X.shape[1],)))\n",
        "model.add(Dense(30,activation='relu'))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import SGD , Adam ,Adagrad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.2708e-07 - val_accuracy: 1.0000 - val_loss: 2.9674e-07\n",
            "Epoch 2/20\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7320e-08 - val_accuracy: 1.0000 - val_loss: 2.2795e-07\n",
            "Epoch 3/20\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1882e-08 - val_accuracy: 1.0000 - val_loss: 1.6587e-07\n",
            "Epoch 4/20\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.8452e-09 - val_accuracy: 1.0000 - val_loss: 1.1986e-07\n",
            "Epoch 5/20\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.4571e-09 - val_accuracy: 1.0000 - val_loss: 9.0621e-08\n",
            "Epoch 6/20\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0878e-09 - val_accuracy: 1.0000 - val_loss: 7.1085e-08\n",
            "Epoch 7/20\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1185e-09 - val_accuracy: 1.0000 - val_loss: 5.7017e-08\n",
            "Epoch 8/20\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4768e-09 - val_accuracy: 1.0000 - val_loss: 4.7205e-08\n",
            "Epoch 9/20\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0325e-09 - val_accuracy: 1.0000 - val_loss: 4.0144e-08\n",
            "Epoch 10/20\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7195e-09 - val_accuracy: 1.0000 - val_loss: 3.4429e-08\n",
            "Epoch 11/20\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4733e-09 - val_accuracy: 1.0000 - val_loss: 2.9933e-08\n",
            "Epoch 12/20\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2938e-09 - val_accuracy: 1.0000 - val_loss: 2.6625e-08\n",
            "Epoch 13/20\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1467e-09 - val_accuracy: 1.0000 - val_loss: 2.3765e-08\n",
            "Epoch 14/20\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0306e-09 - val_accuracy: 1.0000 - val_loss: 2.1557e-08\n",
            "Epoch 15/20\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.3030e-10 - val_accuracy: 1.0000 - val_loss: 1.9515e-08\n",
            "Epoch 16/20\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.4716e-10 - val_accuracy: 1.0000 - val_loss: 1.8093e-08\n",
            "Epoch 17/20\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.8067e-10 - val_accuracy: 1.0000 - val_loss: 1.7066e-08\n",
            "Epoch 18/20\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.2534e-10 - val_accuracy: 1.0000 - val_loss: 1.5860e-08\n",
            "Epoch 19/20\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.7476e-10 - val_accuracy: 1.0000 - val_loss: 1.4875e-08\n",
            "Epoch 20/20\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.3079e-10 - val_accuracy: 1.0000 - val_loss: 1.4055e-08\n"
          ]
        }
      ],
      "source": [
        "\n",
        "opt = Adam(learning_rate=0.001, beta_1 = 0.9 , beta_2 = 0.99)\n",
        "model.compile( loss='binary_crossentropy',optimizer=opt, metrics=['accuracy'])\n",
        "history=model.fit(train_X,train_y,epochs=20,batch_size=64,validation_data=(test_X,test_y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_model ():\n",
        "    model = Sequential([ Dense (64,activation ='relu' , input_shape = (train_X.shape[1],)),\n",
        "    Dense (32 , activation ='relu' ),\n",
        "    Dense (1 , activation ='sigmoid' )])\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "optimizer_grid ={\n",
        "    'Adam':[\n",
        "        {'learning_rate':0.5, 'beta_1':  0.9, 'beta_2':0.99},\n",
        "        {'learning_rate':0.0001, 'beta_1':  0.9, 'beta_2':0.9},\n",
        "        {'learning_rate':0.001, 'beta_1':  0.9, 'beta_2':0.1}\n",
        "    ],\n",
        "    'SGD':[\n",
        "        {'learning_rate':0.5, 'momentum':  0.0},\n",
        "        {'learning_rate':0.0001, 'momentum':  0.9},\n",
        "        {'learning_rate':0.001, 'momentum':  0.5}\n",
        "    ],\n",
        "    'Adagrad': [\n",
        "        {'learning_rate':0.01},\n",
        "        {'learning_rate':0.005}\n",
        "]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "result = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train with Adam and {'learning_rate': 0.5, 'beta_1': 0.9, 'beta_2': 0.99}\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Mgama\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8170 - loss: 2.3479 - val_accuracy: 0.7786 - val_loss: 2.9156\n",
            "Epoch 2/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7362 - loss: 1.4195 - val_accuracy: 0.7324 - val_loss: 0.5292\n",
            "Epoch 3/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7341 - loss: 0.5546 - val_accuracy: 0.7324 - val_loss: 0.5356\n",
            "Epoch 4/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7352 - loss: 1.3984 - val_accuracy: 0.7324 - val_loss: 0.5510\n",
            "Epoch 5/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7346 - loss: 1.4083 - val_accuracy: 0.7324 - val_loss: 0.5814\n",
            "Epoch 6/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7352 - loss: 0.7757 - val_accuracy: 0.7324 - val_loss: 0.6075\n",
            "Epoch 7/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7352 - loss: 0.5856 - val_accuracy: 0.7324 - val_loss: 0.5827\n",
            "Epoch 8/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7352 - loss: 0.5871 - val_accuracy: 0.7324 - val_loss: 0.6058\n",
            "Epoch 9/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7352 - loss: 0.5875 - val_accuracy: 0.7324 - val_loss: 0.5822\n",
            "Epoch 10/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7352 - loss: 0.5873 - val_accuracy: 0.7324 - val_loss: 0.5998\n",
            "Epoch 11/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7352 - loss: 0.5865 - val_accuracy: 0.7324 - val_loss: 0.5817\n",
            "Epoch 12/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7352 - loss: 0.5886 - val_accuracy: 0.7324 - val_loss: 0.5810\n",
            "Epoch 13/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7352 - loss: 0.5814 - val_accuracy: 0.7324 - val_loss: 0.5818\n",
            "Epoch 14/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7352 - loss: 0.5880 - val_accuracy: 0.7324 - val_loss: 0.5808\n",
            "Epoch 15/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7352 - loss: 0.5826 - val_accuracy: 0.7324 - val_loss: 0.5809\n",
            "Epoch 16/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7352 - loss: 0.5864 - val_accuracy: 0.7324 - val_loss: 0.5941\n",
            "Epoch 17/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7352 - loss: 0.5858 - val_accuracy: 0.7324 - val_loss: 0.6052\n",
            "Epoch 18/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7352 - loss: 0.5912 - val_accuracy: 0.7324 - val_loss: 0.6668\n",
            "Epoch 19/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7352 - loss: 0.5884 - val_accuracy: 0.7324 - val_loss: 0.5820\n",
            "Epoch 20/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7352 - loss: 0.5872 - val_accuracy: 0.7324 - val_loss: 0.5809\n",
            "Epoch 21/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7352 - loss: 0.5850 - val_accuracy: 0.7324 - val_loss: 0.6021\n",
            "Epoch 22/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7352 - loss: 0.5857 - val_accuracy: 0.7324 - val_loss: 0.5819\n",
            "Epoch 23/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7352 - loss: 0.5890 - val_accuracy: 0.7324 - val_loss: 0.5808\n",
            "Epoch 24/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7352 - loss: 0.5890 - val_accuracy: 0.7324 - val_loss: 0.5821\n",
            "Epoch 25/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7352 - loss: 0.5839 - val_accuracy: 0.7324 - val_loss: 0.5970\n",
            "Epoch 26/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7352 - loss: 0.5859 - val_accuracy: 0.7324 - val_loss: 0.5907\n",
            "Epoch 27/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7352 - loss: 0.5872 - val_accuracy: 0.7324 - val_loss: 0.5895\n",
            "Epoch 28/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7352 - loss: 0.5851 - val_accuracy: 0.7324 - val_loss: 0.5885\n",
            "Epoch 29/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7352 - loss: 0.5922 - val_accuracy: 0.7324 - val_loss: 0.5815\n",
            "Epoch 30/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7352 - loss: 0.5860 - val_accuracy: 0.7324 - val_loss: 0.5812\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "train with Adam and {'learning_rate': 0.0001, 'beta_1': 0.9, 'beta_2': 0.9}\n",
            "Epoch 1/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7121 - loss: 0.5807 - val_accuracy: 0.8595 - val_loss: 0.4443\n",
            "Epoch 2/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9164 - loss: 0.3323 - val_accuracy: 0.9276 - val_loss: 0.2645\n",
            "Epoch 3/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9650 - loss: 0.1851 - val_accuracy: 0.9737 - val_loss: 0.1454\n",
            "Epoch 4/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9894 - loss: 0.0931 - val_accuracy: 0.9872 - val_loss: 0.0727\n",
            "Epoch 5/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9963 - loss: 0.0434 - val_accuracy: 0.9929 - val_loss: 0.0363\n",
            "Epoch 6/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9977 - loss: 0.0204 - val_accuracy: 0.9965 - val_loss: 0.0200\n",
            "Epoch 7/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9988 - loss: 0.0103 - val_accuracy: 0.9965 - val_loss: 0.0123\n",
            "Epoch 8/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9991 - loss: 0.0059 - val_accuracy: 0.9965 - val_loss: 0.0080\n",
            "Epoch 9/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9991 - loss: 0.0036 - val_accuracy: 0.9986 - val_loss: 0.0054\n",
            "Epoch 10/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0023 - val_accuracy: 0.9986 - val_loss: 0.0036\n",
            "Epoch 11/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0014 - val_accuracy: 0.9986 - val_loss: 0.0027\n",
            "Epoch 12/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 9.0166e-04 - val_accuracy: 0.9993 - val_loss: 0.0019\n",
            "Epoch 13/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.7512e-04 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
            "Epoch 14/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4057e-04 - val_accuracy: 1.0000 - val_loss: 7.3101e-04\n",
            "Epoch 15/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9430e-04 - val_accuracy: 1.0000 - val_loss: 4.9920e-04\n",
            "Epoch 16/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2992e-04 - val_accuracy: 1.0000 - val_loss: 3.1901e-04\n",
            "Epoch 17/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.7420e-05 - val_accuracy: 1.0000 - val_loss: 1.9934e-04\n",
            "Epoch 18/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4238e-05 - val_accuracy: 1.0000 - val_loss: 1.0507e-04\n",
            "Epoch 19/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9181e-05 - val_accuracy: 1.0000 - val_loss: 6.5097e-05\n",
            "Epoch 20/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0811e-05 - val_accuracy: 1.0000 - val_loss: 4.1305e-05\n",
            "Epoch 21/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.4072e-06 - val_accuracy: 1.0000 - val_loss: 2.1997e-05\n",
            "Epoch 22/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6867e-06 - val_accuracy: 1.0000 - val_loss: 1.4899e-05\n",
            "Epoch 23/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4421e-06 - val_accuracy: 1.0000 - val_loss: 7.5925e-06\n",
            "Epoch 24/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.6724e-07 - val_accuracy: 1.0000 - val_loss: 4.1075e-06\n",
            "Epoch 25/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.5907e-07 - val_accuracy: 1.0000 - val_loss: 2.3243e-06\n",
            "Epoch 26/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9035e-07 - val_accuracy: 1.0000 - val_loss: 1.4211e-06\n",
            "Epoch 27/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0751e-07 - val_accuracy: 1.0000 - val_loss: 9.2638e-07\n",
            "Epoch 28/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.7177e-08 - val_accuracy: 1.0000 - val_loss: 6.1501e-07\n",
            "Epoch 29/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.5660e-08 - val_accuracy: 1.0000 - val_loss: 4.5470e-07\n",
            "Epoch 30/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2623e-08 - val_accuracy: 1.0000 - val_loss: 3.4054e-07\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "train with Adam and {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.1}\n",
            "Epoch 1/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8165 - loss: 772570.5625 - val_accuracy: 0.7814 - val_loss: 473975.8750\n",
            "Epoch 2/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7854 - loss: 7999101952.0000 - val_accuracy: 0.7388 - val_loss: 5881416704.0000\n",
            "Epoch 3/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7144 - loss: 60132720419799040.0000 - val_accuracy: 0.7324 - val_loss: 1522691388196519936.0000\n",
            "Epoch 4/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7352 - loss: 1061006799290761216.0000 - val_accuracy: 0.7324 - val_loss: 736011365646336000.0000\n",
            "Epoch 5/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7279 - loss: 826241687868145664.0000 - val_accuracy: 0.4840 - val_loss: 735604546344058880.0000\n",
            "Epoch 6/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4799 - loss: 825779549387096064.0000 - val_accuracy: 0.4840 - val_loss: 735151891150798848.0000\n",
            "Epoch 7/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4801 - loss: 824018612795736064.0000 - val_accuracy: 0.4847 - val_loss: 725416334162132992.0000\n",
            "Epoch 8/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4810 - loss: 814862910751768576.0000 - val_accuracy: 0.4833 - val_loss: 724916193810448384.0000\n",
            "Epoch 9/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4808 - loss: 807656093068034048.0000 - val_accuracy: 0.4833 - val_loss: 717277749093335040.0000\n",
            "Epoch 10/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4904 - loss: 807065380446011392.0000 - val_accuracy: 0.4925 - val_loss: 716540320388481024.0000\n",
            "Epoch 11/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4869 - loss: 806238135385063424.0000 - val_accuracy: 0.4933 - val_loss: 715181255297073152.0000\n",
            "Epoch 12/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5158 - loss: 805452877924401152.0000 - val_accuracy: 0.5280 - val_loss: 708611879479541760.0000\n",
            "Epoch 13/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4263 - loss: 259480157130063872.0000 - val_accuracy: 0.2676 - val_loss: 0.8671\n",
            "Epoch 14/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2648 - loss: 0.8356 - val_accuracy: 0.2676 - val_loss: 0.8022\n",
            "Epoch 15/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2648 - loss: 0.7742 - val_accuracy: 0.2676 - val_loss: 0.7451\n",
            "Epoch 16/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2648 - loss: 0.7209 - val_accuracy: 0.2676 - val_loss: 0.6967\n",
            "Epoch 17/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6880 - loss: 0.6762 - val_accuracy: 0.7324 - val_loss: 0.6544\n",
            "Epoch 18/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7352 - loss: 0.6369 - val_accuracy: 0.7324 - val_loss: 0.6209\n",
            "Epoch 19/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7352 - loss: 0.6051 - val_accuracy: 0.7324 - val_loss: 0.5968\n",
            "Epoch 20/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7352 - loss: 0.5882 - val_accuracy: 0.7324 - val_loss: 0.5851\n",
            "Epoch 21/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7352 - loss: 0.5805 - val_accuracy: 0.7324 - val_loss: 0.5815\n",
            "Epoch 22/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7352 - loss: 0.5785 - val_accuracy: 0.7324 - val_loss: 0.5809\n",
            "Epoch 23/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7352 - loss: 0.5783 - val_accuracy: 0.7324 - val_loss: 0.5808\n",
            "Epoch 24/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7352 - loss: 0.5782 - val_accuracy: 0.7324 - val_loss: 0.5808\n",
            "Epoch 25/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7352 - loss: 0.5781 - val_accuracy: 0.7324 - val_loss: 0.5808\n",
            "Epoch 26/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7352 - loss: 0.5781 - val_accuracy: 0.7324 - val_loss: 0.5808\n",
            "Epoch 27/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7352 - loss: 0.5781 - val_accuracy: 0.7324 - val_loss: 0.5808\n",
            "Epoch 28/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7352 - loss: 0.5781 - val_accuracy: 0.7324 - val_loss: 0.5809\n",
            "Epoch 29/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7352 - loss: 0.5781 - val_accuracy: 0.7324 - val_loss: 0.5808\n",
            "Epoch 30/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7352 - loss: 0.5781 - val_accuracy: 0.7324 - val_loss: 0.5808\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "train with SGD and {'learning_rate': 0.5, 'momentum': 0.0}\n",
            "Epoch 1/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9922 - loss: 0.0230 - val_accuracy: 1.0000 - val_loss: 7.5442e-04\n",
            "Epoch 2/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.6950e-04 - val_accuracy: 1.0000 - val_loss: 3.4372e-04\n",
            "Epoch 3/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7841e-04 - val_accuracy: 1.0000 - val_loss: 2.3304e-04\n",
            "Epoch 4/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1841e-04 - val_accuracy: 1.0000 - val_loss: 1.7508e-04\n",
            "Epoch 5/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.6247e-05 - val_accuracy: 1.0000 - val_loss: 1.3920e-04\n",
            "Epoch 6/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.8033e-05 - val_accuracy: 1.0000 - val_loss: 1.1512e-04\n",
            "Epoch 7/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.5942e-05 - val_accuracy: 1.0000 - val_loss: 9.8942e-05\n",
            "Epoch 8/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7367e-05 - val_accuracy: 1.0000 - val_loss: 8.5988e-05\n",
            "Epoch 9/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0932e-05 - val_accuracy: 1.0000 - val_loss: 7.6372e-05\n",
            "Epoch 10/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.5993e-05 - val_accuracy: 1.0000 - val_loss: 6.8692e-05\n",
            "Epoch 11/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2045e-05 - val_accuracy: 1.0000 - val_loss: 6.2175e-05\n",
            "Epoch 12/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8814e-05 - val_accuracy: 1.0000 - val_loss: 5.7099e-05\n",
            "Epoch 13/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6163e-05 - val_accuracy: 1.0000 - val_loss: 5.2695e-05\n",
            "Epoch 14/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3933e-05 - val_accuracy: 1.0000 - val_loss: 4.8913e-05\n",
            "Epoch 15/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2035e-05 - val_accuracy: 1.0000 - val_loss: 4.5594e-05\n",
            "Epoch 16/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0404e-05 - val_accuracy: 1.0000 - val_loss: 4.2596e-05\n",
            "Epoch 17/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8959e-05 - val_accuracy: 1.0000 - val_loss: 4.0069e-05\n",
            "Epoch 18/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7723e-05 - val_accuracy: 1.0000 - val_loss: 3.7824e-05\n",
            "Epoch 19/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6615e-05 - val_accuracy: 1.0000 - val_loss: 3.5781e-05\n",
            "Epoch 20/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5626e-05 - val_accuracy: 1.0000 - val_loss: 3.3989e-05\n",
            "Epoch 21/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4757e-05 - val_accuracy: 1.0000 - val_loss: 3.2357e-05\n",
            "Epoch 22/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3960e-05 - val_accuracy: 1.0000 - val_loss: 3.0896e-05\n",
            "Epoch 23/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3248e-05 - val_accuracy: 1.0000 - val_loss: 2.9544e-05\n",
            "Epoch 24/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2604e-05 - val_accuracy: 1.0000 - val_loss: 2.8305e-05\n",
            "Epoch 25/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2012e-05 - val_accuracy: 1.0000 - val_loss: 2.7166e-05\n",
            "Epoch 26/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1469e-05 - val_accuracy: 1.0000 - val_loss: 2.6111e-05\n",
            "Epoch 27/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0975e-05 - val_accuracy: 1.0000 - val_loss: 2.5141e-05\n",
            "Epoch 28/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0519e-05 - val_accuracy: 1.0000 - val_loss: 2.4234e-05\n",
            "Epoch 29/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0097e-05 - val_accuracy: 1.0000 - val_loss: 2.3388e-05\n",
            "Epoch 30/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.7066e-06 - val_accuracy: 1.0000 - val_loss: 2.2601e-05\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "train with SGD and {'learning_rate': 0.0001, 'momentum': 0.9}\n",
            "Epoch 1/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4097 - loss: 0.7647 - val_accuracy: 0.5358 - val_loss: 0.6736\n",
            "Epoch 2/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6571 - loss: 0.6228 - val_accuracy: 0.7317 - val_loss: 0.5809\n",
            "Epoch 3/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8055 - loss: 0.5474 - val_accuracy: 0.8254 - val_loss: 0.5233\n",
            "Epoch 4/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8678 - loss: 0.4963 - val_accuracy: 0.8644 - val_loss: 0.4805\n",
            "Epoch 5/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8908 - loss: 0.4552 - val_accuracy: 0.8921 - val_loss: 0.4436\n",
            "Epoch 6/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9033 - loss: 0.4189 - val_accuracy: 0.9013 - val_loss: 0.4099\n",
            "Epoch 7/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9175 - loss: 0.3855 - val_accuracy: 0.9155 - val_loss: 0.3783\n",
            "Epoch 8/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9313 - loss: 0.3540 - val_accuracy: 0.9290 - val_loss: 0.3487\n",
            "Epoch 9/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9434 - loss: 0.3246 - val_accuracy: 0.9390 - val_loss: 0.3210\n",
            "Epoch 10/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9507 - loss: 0.2972 - val_accuracy: 0.9489 - val_loss: 0.2952\n",
            "Epoch 11/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9569 - loss: 0.2719 - val_accuracy: 0.9560 - val_loss: 0.2716\n",
            "Epoch 12/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9629 - loss: 0.2488 - val_accuracy: 0.9631 - val_loss: 0.2498\n",
            "Epoch 13/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9681 - loss: 0.2276 - val_accuracy: 0.9674 - val_loss: 0.2299\n",
            "Epoch 14/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9721 - loss: 0.2084 - val_accuracy: 0.9716 - val_loss: 0.2118\n",
            "Epoch 15/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9771 - loss: 0.1910 - val_accuracy: 0.9730 - val_loss: 0.1954\n",
            "Epoch 16/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9798 - loss: 0.1753 - val_accuracy: 0.9737 - val_loss: 0.1806\n",
            "Epoch 17/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9814 - loss: 0.1612 - val_accuracy: 0.9752 - val_loss: 0.1671\n",
            "Epoch 18/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9856 - loss: 0.1485 - val_accuracy: 0.9759 - val_loss: 0.1550\n",
            "Epoch 19/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9865 - loss: 0.1370 - val_accuracy: 0.9773 - val_loss: 0.1439\n",
            "Epoch 20/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9883 - loss: 0.1266 - val_accuracy: 0.9794 - val_loss: 0.1339\n",
            "Epoch 21/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9902 - loss: 0.1173 - val_accuracy: 0.9830 - val_loss: 0.1248\n",
            "Epoch 22/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9909 - loss: 0.1089 - val_accuracy: 0.9837 - val_loss: 0.1165\n",
            "Epoch 23/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9917 - loss: 0.1013 - val_accuracy: 0.9844 - val_loss: 0.1090\n",
            "Epoch 24/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9931 - loss: 0.0943 - val_accuracy: 0.9865 - val_loss: 0.1021\n",
            "Epoch 25/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9938 - loss: 0.0881 - val_accuracy: 0.9872 - val_loss: 0.0958\n",
            "Epoch 26/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9943 - loss: 0.0824 - val_accuracy: 0.9872 - val_loss: 0.0901\n",
            "Epoch 27/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9945 - loss: 0.0772 - val_accuracy: 0.9879 - val_loss: 0.0848\n",
            "Epoch 28/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9950 - loss: 0.0724 - val_accuracy: 0.9894 - val_loss: 0.0799\n",
            "Epoch 29/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9954 - loss: 0.0681 - val_accuracy: 0.9901 - val_loss: 0.0755\n",
            "Epoch 30/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9959 - loss: 0.0642 - val_accuracy: 0.9908 - val_loss: 0.0714\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "train with SGD and {'learning_rate': 0.001, 'momentum': 0.5}\n",
            "Epoch 1/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6425 - loss: 0.6553 - val_accuracy: 0.8105 - val_loss: 0.5700\n",
            "Epoch 2/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8475 - loss: 0.5275 - val_accuracy: 0.8978 - val_loss: 0.4767\n",
            "Epoch 3/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9088 - loss: 0.4428 - val_accuracy: 0.9340 - val_loss: 0.4021\n",
            "Epoch 4/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9482 - loss: 0.3709 - val_accuracy: 0.9567 - val_loss: 0.3367\n",
            "Epoch 5/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9705 - loss: 0.3077 - val_accuracy: 0.9752 - val_loss: 0.2800\n",
            "Epoch 6/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9807 - loss: 0.2537 - val_accuracy: 0.9844 - val_loss: 0.2323\n",
            "Epoch 7/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9885 - loss: 0.2089 - val_accuracy: 0.9851 - val_loss: 0.1930\n",
            "Epoch 8/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9897 - loss: 0.1727 - val_accuracy: 0.9872 - val_loss: 0.1613\n",
            "Epoch 9/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9922 - loss: 0.1437 - val_accuracy: 0.9879 - val_loss: 0.1361\n",
            "Epoch 10/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9938 - loss: 0.1207 - val_accuracy: 0.9894 - val_loss: 0.1159\n",
            "Epoch 11/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9950 - loss: 0.1023 - val_accuracy: 0.9908 - val_loss: 0.0997\n",
            "Epoch 12/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9957 - loss: 0.0876 - val_accuracy: 0.9915 - val_loss: 0.0867\n",
            "Epoch 13/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9972 - loss: 0.0758 - val_accuracy: 0.9915 - val_loss: 0.0762\n",
            "Epoch 14/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9972 - loss: 0.0662 - val_accuracy: 0.9929 - val_loss: 0.0676\n",
            "Epoch 15/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9977 - loss: 0.0583 - val_accuracy: 0.9936 - val_loss: 0.0604\n",
            "Epoch 16/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9979 - loss: 0.0518 - val_accuracy: 0.9943 - val_loss: 0.0544\n",
            "Epoch 17/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9980 - loss: 0.0464 - val_accuracy: 0.9943 - val_loss: 0.0493\n",
            "Epoch 18/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9982 - loss: 0.0418 - val_accuracy: 0.9957 - val_loss: 0.0450\n",
            "Epoch 19/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9984 - loss: 0.0378 - val_accuracy: 0.9957 - val_loss: 0.0413\n",
            "Epoch 20/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9986 - loss: 0.0345 - val_accuracy: 0.9957 - val_loss: 0.0381\n",
            "Epoch 21/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9986 - loss: 0.0316 - val_accuracy: 0.9957 - val_loss: 0.0354\n",
            "Epoch 22/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9988 - loss: 0.0291 - val_accuracy: 0.9957 - val_loss: 0.0330\n",
            "Epoch 23/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9989 - loss: 0.0269 - val_accuracy: 0.9957 - val_loss: 0.0308\n",
            "Epoch 24/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9989 - loss: 0.0250 - val_accuracy: 0.9957 - val_loss: 0.0289\n",
            "Epoch 25/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9989 - loss: 0.0233 - val_accuracy: 0.9965 - val_loss: 0.0273\n",
            "Epoch 26/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9989 - loss: 0.0218 - val_accuracy: 0.9965 - val_loss: 0.0257\n",
            "Epoch 27/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9989 - loss: 0.0204 - val_accuracy: 0.9965 - val_loss: 0.0244\n",
            "Epoch 28/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9989 - loss: 0.0192 - val_accuracy: 0.9965 - val_loss: 0.0231\n",
            "Epoch 29/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9991 - loss: 0.0181 - val_accuracy: 0.9965 - val_loss: 0.0220\n",
            "Epoch 30/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9991 - loss: 0.0171 - val_accuracy: 0.9965 - val_loss: 0.0209\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "train with Adagrad and {'learning_rate': 0.01}\n",
            "Epoch 1/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9210 - loss: 0.2747 - val_accuracy: 0.9929 - val_loss: 0.0845\n",
            "Epoch 2/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9977 - loss: 0.0436 - val_accuracy: 0.9979 - val_loss: 0.0270\n",
            "Epoch 3/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9984 - loss: 0.0176 - val_accuracy: 0.9979 - val_loss: 0.0148\n",
            "Epoch 4/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0103 - val_accuracy: 0.9986 - val_loss: 0.0101\n",
            "Epoch 5/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0071 - val_accuracy: 0.9986 - val_loss: 0.0076\n",
            "Epoch 6/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0053 - val_accuracy: 0.9993 - val_loss: 0.0060\n",
            "Epoch 7/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 0.0042 - val_accuracy: 0.9993 - val_loss: 0.0050\n",
            "Epoch 8/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.9993 - val_loss: 0.0043\n",
            "Epoch 9/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.9993 - val_loss: 0.0037\n",
            "Epoch 10/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.9993 - val_loss: 0.0033\n",
            "Epoch 11/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 1.0000 - val_loss: 0.0029\n",
            "Epoch 12/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 1.0000 - val_loss: 0.0026\n",
            "Epoch 13/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 1.0000 - val_loss: 0.0024\n",
            "Epoch 14/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 0.0022\n",
            "Epoch 15/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 1.0000 - val_loss: 0.0020\n",
            "Epoch 16/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 0.0019\n",
            "Epoch 17/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 0.0018\n",
            "Epoch 18/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
            "Epoch 19/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.9267e-04 - val_accuracy: 1.0000 - val_loss: 0.0015\n",
            "Epoch 20/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.2467e-04 - val_accuracy: 1.0000 - val_loss: 0.0015\n",
            "Epoch 21/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.6465e-04 - val_accuracy: 1.0000 - val_loss: 0.0014\n",
            "Epoch 22/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.1125e-04 - val_accuracy: 1.0000 - val_loss: 0.0013\n",
            "Epoch 23/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.6299e-04 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
            "Epoch 24/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.1964e-04 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
            "Epoch 25/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.8076e-04 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
            "Epoch 26/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.4521e-04 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
            "Epoch 27/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.1302e-04 - val_accuracy: 1.0000 - val_loss: 0.0010\n",
            "Epoch 28/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.8368e-04 - val_accuracy: 1.0000 - val_loss: 9.8331e-04\n",
            "Epoch 29/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.5684e-04 - val_accuracy: 1.0000 - val_loss: 9.4456e-04\n",
            "Epoch 30/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.3194e-04 - val_accuracy: 1.0000 - val_loss: 9.0624e-04\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "train with Adagrad and {'learning_rate': 0.005}\n",
            "Epoch 1/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8979 - loss: 0.3708 - val_accuracy: 0.9730 - val_loss: 0.2023\n",
            "Epoch 2/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9865 - loss: 0.1321 - val_accuracy: 0.9957 - val_loss: 0.0901\n",
            "Epoch 3/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9970 - loss: 0.0624 - val_accuracy: 0.9972 - val_loss: 0.0507\n",
            "Epoch 4/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9982 - loss: 0.0363 - val_accuracy: 0.9972 - val_loss: 0.0335\n",
            "Epoch 5/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9991 - loss: 0.0243 - val_accuracy: 0.9972 - val_loss: 0.0246\n",
            "Epoch 6/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0178 - val_accuracy: 0.9972 - val_loss: 0.0194\n",
            "Epoch 7/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0138 - val_accuracy: 0.9986 - val_loss: 0.0159\n",
            "Epoch 8/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0111 - val_accuracy: 0.9986 - val_loss: 0.0135\n",
            "Epoch 9/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0093 - val_accuracy: 0.9986 - val_loss: 0.0117\n",
            "Epoch 10/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0079 - val_accuracy: 0.9986 - val_loss: 0.0103\n",
            "Epoch 11/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0068 - val_accuracy: 0.9986 - val_loss: 0.0092\n",
            "Epoch 12/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0060 - val_accuracy: 0.9993 - val_loss: 0.0083\n",
            "Epoch 13/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 0.0053 - val_accuracy: 0.9993 - val_loss: 0.0076\n",
            "Epoch 14/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0048 - val_accuracy: 0.9993 - val_loss: 0.0070\n",
            "Epoch 15/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.9993 - val_loss: 0.0065\n",
            "Epoch 16/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.9993 - val_loss: 0.0060\n",
            "Epoch 17/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.9993 - val_loss: 0.0057\n",
            "Epoch 18/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.9993 - val_loss: 0.0053\n",
            "Epoch 19/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.9993 - val_loss: 0.0050\n",
            "Epoch 20/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.9993 - val_loss: 0.0048\n",
            "Epoch 21/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.9993 - val_loss: 0.0045\n",
            "Epoch 22/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.9993 - val_loss: 0.0043\n",
            "Epoch 23/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.9993 - val_loss: 0.0041\n",
            "Epoch 24/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.9993 - val_loss: 0.0039\n",
            "Epoch 25/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9993 - val_loss: 0.0038\n",
            "Epoch 26/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9993 - val_loss: 0.0036\n",
            "Epoch 27/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9993 - val_loss: 0.0035\n",
            "Epoch 28/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9993 - val_loss: 0.0034\n",
            "Epoch 29/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9993 - val_loss: 0.0032\n",
            "Epoch 30/30\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9993 - val_loss: 0.0031\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
          ]
        }
      ],
      "source": [
        "for opt_name , config in optimizer_grid.items():\n",
        "    for cfg in config:\n",
        "        print(f\"train with {opt_name} and {cfg}\")\n",
        "        model = create_model()\n",
        "\n",
        "        if opt_name == 'Adam':\n",
        "            opt = Adam(**cfg)\n",
        "        elif opt_name == 'SGD':\n",
        "            opt = SGD(**cfg)\n",
        "        elif opt_name == 'Adagrad':\n",
        "            opt = Adagrad(**cfg)\n",
        "\n",
        "\n",
        "        model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "        history = model.fit(train_X, train_y, epochs=30, batch_size=32, validation_data=(test_X, test_y), verbose=0)\n",
        "        y_pred = (model.predict(test_X) > 0.5).astype(int).flatten()\n",
        "        acc = np.mean(y_pred == test_y)\n",
        "        result.append({'optimizer':opt_name, 'config':cfg, 'test_accuracy':acc})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  optimizer                                             config  test_accuracy\n",
            "1      Adam  {'learning_rate': 0.0001, 'beta_1': 0.9, 'beta...       1.000000\n",
            "3       SGD            {'learning_rate': 0.5, 'momentum': 0.0}       1.000000\n",
            "6   Adagrad                            {'learning_rate': 0.01}       1.000000\n",
            "7   Adagrad                           {'learning_rate': 0.005}       0.999290\n",
            "5       SGD          {'learning_rate': 0.001, 'momentum': 0.5}       0.996451\n",
            "4       SGD         {'learning_rate': 0.0001, 'momentum': 0.9}       0.990774\n",
            "2      Adam  {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_...       0.732434\n",
            "0      Adam  {'learning_rate': 0.5, 'beta_1': 0.9, 'beta_2'...       0.732434\n"
          ]
        }
      ],
      "source": [
        "results_df = pd.DataFrame(result)\n",
        "results_df = results_df.sort_values(by='test_accuracy', ascending=False)\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "plt.Figure(figsize=(12,6))\n",
        "sns .barplot(x='optimizer', y='test_accuracy', hue = 'optimizer' , data = results_df)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
